{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression Models on chemical reactions\n",
    "\n",
    "> Here we show how simple it is to train reaction BERTs on any regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available tools\n",
    "\n",
    "BERT and related transformer models have revolutionised Natural Language Processing. The implementation of such models is conveniently made available through the [Huggingface Transformers](https://github.com/huggingface/transformers) library. We based already based our previous work on reaction fingerprints / classification and atom-mapping on this library. To train the yield regression models in this work, we used the [SimpleTransformers.ai](https://simpletransformers.ai), which contains all you need to add fine-tuning heads on top of transformers, run trainings and evaluations.\n",
    "\n",
    "## SmilesTokenizer\n",
    "\n",
    "One key difference compared to human languages, when compared to chemistry are the tokens and tokenizers. In this work, we use the tokenizer introduced our previous [rxnfp](https://rxn4chemistry.github.io/rxnfp/) work with the same regex as in the [Molecular Transformer](https://github.com/pschwllr/MolecularTransformer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n",
      "Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', '(', 'C', ')', '[C@@H]', '(', 'C', ')', 'C', 'C', 'Br', '.', '[Na]', 'C', '#', 'N', '>>', 'C', 'C', '(', '[C@@H]', '(', 'C', ')', 'C', 'C', 'C', '#', 'N', ')', 'C']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAACWCAIAAACNeWFmAAAYc0lEQVR4nO3de1hU5b4H8N+MzoCAoMlVUEFlm4oBZm4N1C6UmVRqh6csp47aJrMac/cU7soz6vFsaXdj95A1e5+yMbVCt56Nl2KXCokX0ITERNmGAqIzDKAwXGeYWeePV0e8gAOsmTXyfj8Pf8CwZubHZdZ3vb/1rndkgiAQAAAAr+RSFwAAACAlBCEAAHANQQgAAFxDEAIAANcQhAAAwDUEIQAAcA1BCAAAXEMQAgAA1xCEAADANQQhAABwDUEIAABcQxACAADXEIQAAMA1BCEAAHANQQgAAFxDEAIAANcQhAAAwDUEIQAAcA1BCAAAXEMQAgAA1xCEAADANQQhAABwDUEIAABcQxACAADXEIQAAMA1BCEAAHANQQgAAFxDEAIAANcQhAAAwDUEIQAAcA1BCAAAXEMQAgAA1xCEAADANQQhAABwDUEIAABcQxACAADXEIQAAI7avXv3J598curUKakLATEhCAEAHLVx48ZXXnklNzdX6kJATH2lLuAmrFarwWCw2WxhYWFS1wIAcFVVVRURBQYGSl0IiMkdR4QlJSWhoaEPPfSQ1IUAAFwDQdgruWMQenl5EVFTU5PUhQAAXANB2CshCAEAHIUg7JUQhAAADjGZTM3NzV5eXt7e3lLXAmJyxyDs16+fTCZrbm4WBEHqWgAALmPDwaCgIKkLAZG5YxDK5XJPT09BEJqbm6WuBQDgMvRFeyt3DEJCdxQA3A+CsLdCEAIAOARB2FshCAEAHIIg7K3cOghxjhAA3IfRaCSigIAAqQsBkbl1EGJECADuA7NGeysEIQCAQ9Aa7a0QhAAADkEQ9lYIQgAAhyAIeys3DcJ+/foRghAA3IbNZqupqZHJZP7+/lLXAiJz0yDEiBAA3EpNTU1bW9ugQYP69nXHt3GFnkAQAgDcGvqivZibBiFrjeI6QgBwEwjCXsxNgxAjQgBwKwhC1zAYSKt19ZMiCAEAbg1B6GxnztCSJRQRQYsW0cGDLn1qNz3riyAEALeC9dWcp7CQ3n2XNm8mq5Xkcpo9m/z8rn63upr8/EihICJqaCClkpRKkQvAiBAA4NYwInSG3Fx67DEaP56++YbkclKpqKiItm6lMWMub9DQQAEBlJJy+cvXXqNdu8QvAyPC21hTfS0R9emr8PDqL3UtAL0cglBENpuQmSl79106dIiIyMeH/vAH+uMfKSzsJhsHBlJWFlVU0JAhzqoHQXi7Mrc0fvif44fHTLVazKYa/RNLPgwdNV7qogB6LQShKCwWy9dff/3uu+/K5XnHj/v4+9PLL9Orr9KgQddvWVtLgkAeHqRQ0Ftv0YoV9PnnzqoKrdHbmKe33zP/tV7139/E/cfL+Tu/JCJLa3P5r3nV504X/PC11NUB9CoGg4EQhD3Q2NiYlpY2YsSI559//sSJE0OG/O9f/0plZbRixfUpaDDQihU0fDj9+c+Xb5k7lwoK6ORJZ9WGEeFtTLBZq8+dtrZZSgt/Gjwymoga66ozUpOjpj4RPHys1NUB9CoIwm6rrq5OT09PT0+vqakhopEjR77xxhvz589n81/aO3mS3nuPNmwgs5mIqKzs8u1yOa1aRW+/TQMHOqVCjAi7oLW1deXKlZs3b16xYkV9fb3U5ZC5penA1k8P/p+29vzZwGF3shv7Kj0eeWFlzINPSVsbQK/x448/xsfH22w2b2/v1NRUi8UidUW3Db1ev2zZsvDw8JUrV9bU1IwfP16n0506dSo5OVlxbQwWFNBzz1FUFH3xBbW1UWIi5eXRli1XN0hMJKORjhxxTqGCW6qoqCCi0NBQqQu5Kjs7e9SoUUQ0cOBAIvL39//ggw+am5slKaapvralyfTevLvYlxf1ZR/NnyAIwkVD+edvPC5JSQC9jNlsXr9+fVRUFNtV+vj4yOVyIpo0aVJJSYnU1d0GVq9ezdJOJpM9+uijP/30000327dPSEwUiAQiQakUVCrh5Mmr3zWZBHsO7NsnEAnbtolfqpu2Ro8dO0ZE1dXVWVlZ06dPl7aYS5cuaTSa9PR0m80WGRmpVqu3bt26d+/e119//aOPPlq+fPmCBQtcuQ7vidztOz97a9rTS+23NJsuCYLgsgJ6h1mzZjU0NHT0XYXCy2LJ7OTuQUG0caMTygI30Nra+u23365evfrf//43EQUHB7/44otLly799ddfn3vuuUOHDkVHR69Zs0atVstkMqmLdV+jRo2yWq2JiYkajWbChAnXfddmo507afVqys8nIurfn+bPpzffpNDQazbz8aGKisufx8eTs/Zz4mdrz1y8eDE5OVkmk9n/w6ZNm3bgwAGp6snIyGBnBRQKRUpKSktLC7v9hx9+uPvuu1mF4eHhWq22ra3N2cXUVJbq3kpakRiyIjHkm/+Zv2rW0L+/PvPvr8/ULnn49M97BSeMCBsaGkwmk4gP6D58fX07eV14ePixQ9SOPoYMkfoHACeoq6tLS0sLCQlh/wYjRoxIS0tr3/ipq6tLTk5m350+fXplZaWE1bo5q9V65syZG29vaWnRarWTJs3x8BCIhOBgITVVuHTpJo9gNAoajRAdLZjNzi1VJrjTSGL79u2LFy8+d+6cQqFYsmRJeHj4qlWr2KzlhISEv/zlL7GxsS4r5syZMy+99FJWVhYRTZkyRavVjh49uv0GgiBs2bLlnXfeKSkpIaKxY8dqNJqkpCRnFGNrsxzepdv9VaqlpcnTxy/h+bfHT3/WBUej/v7+NTU1JpPJx8fH2c/lYtnZ2W1tbR19Vy7va7Pd18ndPT0pPl78qkAqBoPh008/TUtLq6urI6LY2NjXXnvt2Wef7dOnz40bb9myZdGiRTU1NQEBAX/7299mzZrl6nKJiOhf//rX+++/P3v2bCJatGiR+w9P6+vr2S9Zr9cT0ezZv0yfftfzz5On5/Vbnj1LH3xAX3xBbKLI9u2UmOjMypybsw47d+4c+3MSUVxc3PHjx9ntJpMpNTWVHbzLZLKkpCQXdOctFktaWhrb9Q8YMCAtLc1qtXa0sdVqzcjIiIiIYMVPnjx5z5494tZTfuLwJ4vvYwPBjNTkxkvV4j5+JwYNGkREvXVQCCAIwunTp9VqteeVnXFcXFxmZuYt76XX62fOnMnuolKp6uvrXVAq09bW9u2339pHBazyGTNmXLhwwWU1dFVVVZVGoxl4ZdLnXXfdpdPpLBbLjVsWFQkqlaBQCESCTCYkJgq5uU4vT/ogZKnTv39/IvLz87tp6hiNxpSUFPb3VigUycnJzutIHD161N7OTkpKMhgMjtyrtbVVq9UGBQWxOyYkJPz88889L6aloe477TsrHwtdkRjy1z9M/q0gp+eP2SUuC0Kj0Wi+0v4wmUytra3OfkZRGI1XmzYmk3CbVO0u/vSnP+3bt0/CAo4ePapSqdiYTy6XJyYm5ufnO353m82m1Wq9vb2JKDw8PCfH6S/P1tZWnU7HZu0RUWBgoEaj0el0/v7+7Kh906ZNzq6hq0pLS9VqNXtnPftxhs1mu3FLNmtGJhOIBLlcSEwUjhxxUZESB2FBQcE999zDfkGJiYkVFRWdbFxeXp6cnMympSiVyuTkZAdTykENDQ0pKSnsVREREfH999939RHY+NXPz88+fj116lS36ynK3fX+czErEkNWzRq6e32qpbWl2w/Vba4JQpPJRERLly5lXy5cuHCbM2aGic1kEoiEK1ULCxc6ZT5bb7Vnzx72Mnn66afLy8td/Oz79u1LvNJrUyqVKpXqZPupil1x4sQJNl2gT58+KSkpTjqGq6+vT0tLC70ykyQiIiItLa2pqYl9V6/X23+cpKSkixcvOqOGrvrll19UKhXbY7PjjJvO9rDZbDt2fD9tmo2dfffyEl59VTh71qWlShaEjY2N9tQJDQ39xz/+4eAdi4uLk5KSWDfcx8cnJSWlrq6u5/VkZmYOHTqUiPr27atWq3uy66+urk5JSWFHQHK5PCkpqbS0tEuPUFlZ+eSTT06Pi1n5WOjnbzxWVdbNl2jPuSwIAwMDx4wZw3aI9iDcv3+/VqvdunWr2WxOT08P6bH4+HhHNhs+3BYSInT+MWGCYDIJgYHCmDEC242LHoQffvhhN0523I7uueceMX9xHbNarZmZmRMnTmTP279/f7Vafe7cuR4+rMVi0Wg0bG82bty4X375RZRqGYPB0L6pGB0dfdOmYvvh6bBhw7Kzs0Wsoav27t37wgsvsL20UqmcP39+cXHxjZuxPwc7jIiLK/X1FdRq4fx519crURDu3Llz2LBhRCSXy5OTk7vRXj927Jh9Woq/v39qamq3L+k7f/68SqViDxUbG3v48OHuPc51Kioqrhu/6vX6W96rra2t/enJ7O2bbLYOT0+6gMuCMDQ0dMOGDQsWLBCuBKHZbF62bFlGRsby5ctnz569Zs2anu9wr5vu1BEvr87mi9pnjbIrnDZsEBYsEAQEYQ+4IAhv2lSsra0V8SkOHjw4cuRIIvL09ExNTe1kYoGDHG8q2hUXF7MzO3K5XK1Wu/gUg81my8zMnDx5MhFFR0d7e3ur1eqbDvcbGxs//vjj8PBw9qOFhYWtXbtVwqkIrg7CCxcu2FMnJiYmLy+vJ4+2f//+qVOnskcbMmSIVqu96dnXjrBjKDYTx8vLKzU1VfRLIM6cOZOcnMyuw2Xj10s3nSYsCIIgFBYW/v73v2c/zi0bxaLLzc19+wbsRfjmm29ed/vOnTtFfGoWhFarNTY2tri42D4iNBqN//znP7/66quwsLCamprKHjt//rxjm9kqK4XOPwyGy0FotQqxsUJxMVqjXeOy1mjnTUXRn8t+cUVCQkK3x5o3NhUPHjzo4H0tFktqaiq7kj0qKqqwsLB7NXRJa2vrunXr7Aea/v7+bCmZG7e85QUqknBdENpsNp1Ox0YY4qbODz/8YJ9Adeedd2ZkZHR+0MQcO3Zs0qRJ9tQpKysTpZibKioqso9fBw0alJqaet3rsKmpSaPRsP/dwYMHO94oFtF7773n+CH8kiVLRHxqFoSCIGzfvn3OnDksCEtKSmJjY9euXbt58+ahQ4cajUYRn1EU9jUvtm8X5sxBEHaZsyfLONhUFN2uXbvYjn7AgAEbNmzo0n3ZyUt7U1GlUp04caIbNRw6dCgyMlLE4WlHGhoa0tLShlx5h6Rhw4alpaU1NDTcuKVer9doNH5X3nI3NjZWp9O54PJrR7goCEtKSu6//3728z/66KNnxT4Tyq5hYH0JIho3blxGRkZHG7PUUSqVRBQSEqLT6cQtpiMHDhy477777K0A+/h1165drEXQ7UaxKPLy8tbcgC36unLlyutu//HHH0V8ansQCoIwZcqU6Ojobdu2rVu3bvny5YIgVFVVeXl5uXMQCoIwZYoQHY0gdC/2y/seeOCBrKwsVz61wWB4/PHH2bMnJSXdsgfLzpaxpiLrHnXUVHRcU1OTfe2bBx98UPQOk9Fo1Gg0g668c0RUVJROpzN3fOn7vHnzWA/gkUce2bt3r7jF9JDTg9BsNqempnp4eBBRcHCwU1PHbDZrtdrBgwezP0xcXNyNE5rtS4bKZLLk5GRRJtp0yY4dO2JiYliFI0eOtLd2x48ff8Rlk4Ud5spzhOzzffv2EdG2bdvKy8tHjx49b968p556KjIyUvQgvHTp0sWOXbp06eJFoZOPujoXrYII3ZabmztnzpwuXREhLp1Ox873Dx06tKNdv9ls1ul0Y668I7u/v79Go7lpU7F7vvvuOzY89fPz++qrr0R5zLNnz6rVajYxh4juvvtunU53y0FnYWHh3LlzCwoKRKlBXM4Nwp9++ol1jWUymUqlqq52xZXg7F2v7O+WkpCQwH71NTU1bPE2NmR0vOcuOpvNlpGR8bvf/Y51Elij2AUdm26Q9oJ6s9ks7hUy7WGJNXCB0tLSuLg4tg9Uq9X2NRoFQTCZTDc2FRsbG0Wvoaqq6oknnrAPT3uSskVFRSqVyv7GEQ4uPuD+nBWEtbW19tSJjIwUfbGVW7p48eLbb7/NjlnkcvnUqVPvuOMOIurXr9+aNWs6Gb+7jMVi2bhxY2FhoeiNYhH14pVlhg4d6texwMAhfn5CJx9RUVL/AHCbaD97ZezYsQUFBaypyPZIjjQVRdF+eNqNHfKRI0dUKhWb98fm74g1wd4dOCUIO1qo2vXsS9Kww65p06Z1+7JZPvXiIARwJfvsFaVSaV/OLT4+fseOHY5M7hNFaWnplClT7CeGHBx9tl98wMPDQ6VS9b53oRI5CGtrax966CH2K7v//vt7sq6KiM6cOZOfn797926pC7n9IAgBxMJmr0ycONHHxychISHXBWto3oANT9lUwbFjxx49erSjLdn8Hft6k76+vmq1+rwkl7s7n8hBaLVa77333oEDB2q1Wpcd5jji8OHD4l48ywkEIYC4WlpaqqqqpK0hPz+fzRlUKBQajea6axhaWlp0Oh0bvxJRUFCQRqNxk2XbnET81ujp06cl/zPfaO3atUVFRVJXAQC8+/jjj91hkND+4op777339OnTgrte7e4C7vV+hM5z5MiR4ODgsLAwqQsBAK69/PLLn3zyidRVXPbdd98tXLjwwoULvr6+U6dOzcnJYSvgT5w4MSUlZdasWWx2TK/HxQ9JRGVlZYWFhVJXAQC8U6vVUpdw1YwZM06cODF37tz6+vqCggKTycSuiMjLy5szZw4nKUhEvIwIFy9eLJfL09PTpS4EAPhVVlY2c+bMgoIC+6V4bmLPnj19+vTx9fW1L1fJlb5SF+AiTz75pNlslroKAODa+fPnKyoq3C0FieiBBx6QugQp8TLyzcvL27p1q9RVAADXYmJi8vPzpa4CrsdLa3TKlCkHDx5sa2uTuhAA4FdSUtL+/ftPnjzZ+Qp/4GK8tEaXLVvGVthj04UBAFyvsrKyurq6f//+UhcC1+AlCL/++uvq6urBgwcnJCRIXQsA8MhsNmdmZra1teFw3N3wco5w586dWVlZpaWlUhcCAJzKz88PCAgIDw/X6/VS1wLX4GVEuH79eoVCMXbsWKkLAQBONTY2+vj4NDY22t93AtwEF5NlKisr582bZzKZxowZs379eqnLAQAenTp1SqFQ+Pn52d/VHdwEFyNCm82WnZ1NRDykPgC4J5VKdfjwYSI6ffr0iBEjpC4HruIiCIOCgvbs2ePr64vJWgAgldDQ0KqqKqPRGBAQIHUtcA0uWqN79ux55ZVXWltb6+vrc3JyxowZI3VFAMAXvV5/9OjRwMDAoKCgkJCQvn25GITcLrj4Y7S0tBQXF7PP2drqAACulJ2dPXfuXPZ5UVFRVFSUtPVAe1wEYXx8/K+//urp6dm/f/8BAwZIXQ4AcOeOO+6YMWOGwWAwGAyBgYFSlwPX4CIIv/zyy1WrVlkslvr6+pdeemnt2rVSVwQAfKmqqnrmmWcCAgJCQkIwWcHdcBGELS0tNTU17PPm5mZpiwEADi1btqyyspJ9fvjw4QkTJkhbD7THxWSZuro6i8VitVqVSmVDQ8OQIUOkrggA+JKSklJZWclao7t27QoLC5O6IriKixHh4sWLN23axD6Xy+VY6w8AXOnQoUNKpXLixIkBAQHBwcFojbobLoJQLpcTkYeHh5eXl4+Pj9ls9vDwkLooAODFgQMHVq9ebf8yJydn6tSpEtYD1+GiNVpbWyuTyViDtL6+Pjw8HEscAYDL5OfnZ2VlGY3GqqoqvV7/xRdfDB8+XOqi4CouRoSTJ08uKSmxf/nZZ5+9+OKLEtYDAFzRarWenp4BAQGjRo0KCgry9vaWuiK4BhdBOGjQoIEDB/r6+rIVb9GgBwCXsdls69evb2trs9+SlZX18MMPS1gSXKf3B6EgCJs2bWJN0ZaWlubmZoVCIXVRAMALtgsyGAzV1dVGo/HChQvh4eFSFwXX6P1B2NraGhER0f6WmJiYgoICqeoBAK5s2LBh3bp1wcHBbKHRcePGKZVKqYuCa/T+IPT09IyIiOjTp4+fn59SqfT29o6MjJS6KADgxfHjx3Nyctrfsm3bNgwK3QoXs0YBAKRSXl7+22+/6fV6o9FoNBoNBsPSpUtHjx4tdV1wFYIQAAC4Jpe6AAAAACkhCAEAgGsIQgAA4BqCEAAAuIYgBAAAriEIAQCAawhCAADgGoIQAAC4hiAEAACuIQgBAIBrCEIAAOAaghAAALiGIAQAAK4hCAEAgGsIQgAA4BqCEAAAuIYgBAAAriEIAQCAawhCAADgGoIQAAC4hiAEAACuIQgBAIBrCEIAAOAaghAAALiGIAQAAK4hCAEAgGsIQgAA4BqCEAAAuIYgBAAAriEIAQCAawhCAADgGoIQAAC4hiAEAACuIQgBAIBrCEIAAODa/wPul9kxjkaxtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<rdkit.Chem.rdChemReactions.ChemicalReaction at 0x7f7c54b47300>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rxnfp.tokenization import get_default_tokenizer, SmilesTokenizer\n",
    "from rdkit.Chem import rdChemReactions\n",
    "\n",
    "smiles_tokenizer = get_default_tokenizer()\n",
    "\n",
    "reaction_smiles = 'CC(C)[C@@H](C)CCBr.[Na]C#N>>CC([C@@H](C)CCC#N)C'\n",
    "rxn = rdChemReactions.ReactionFromSmarts(reaction_smiles,useSmiles=True)\n",
    "\n",
    "print(smiles_tokenizer.tokenize(reaction_smiles))\n",
    "rxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tokenizer is normally hard-coded in the SimpleTransformers library we need to change it, we therefore create a `SmilesClassificationModel` class, as seen in the `core` module. \n",
    "\n",
    "```python\n",
    "MODEL_CLASSES = {\n",
    "            \"bert\": (BertConfig, BertForSequenceClassification, SmilesTokenizer),\n",
    "        }\n",
    "```\n",
    "\n",
    "Once this is done, the SimpleTransformers library can be used as usual. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained reaction BERT models\n",
    "\n",
    "There are currently two reaction BERT models in the `rxnfp` library - `pretrained` (trained with on a reaction MLM task) and `ft` (additionally trained on a reaction classification task). For this example, we will use the `pretrained` model as starting point for the training of our Yield-BERT. On the Buchwald-Hartwig reactions both base models performed similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n",
      "Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import torch\n",
    "from rxnfp.models import SmilesClassificationModel\n",
    "model_path =  pkg_resources.resource_filename(\n",
    "                \"rxnfp\",\n",
    "                f\"models/transformers/bert_pretrained\" # change pretrained to ft to start from the other base model\n",
    ")\n",
    "yield_bert = SmilesClassificationModel('bert', model_path, use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "Load the reaction SMILES and yield values into a DataFrame with columns `['text', 'labels']`.\n",
    "\n",
    "The same procedure could be applied to any reaction (or molecule) regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1...</td>\n",
       "      <td>1.387974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brc1ccccn1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C...</td>\n",
       "      <td>-0.796876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2...</td>\n",
       "      <td>-0.827835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCOC(=O)c1cnoc1.CN1CCCN2CCCN=C12.COc1ccc(OC)c(...</td>\n",
       "      <td>-0.464841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CN1CCCN2CCCN=C12.COc1ccc(Cl)cc1.COc1ccc(OC)c(P...</td>\n",
       "      <td>-1.186082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1...  1.387974\n",
       "1  Brc1ccccn1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C... -0.796876\n",
       "2  CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2... -0.827835\n",
       "3  CCOC(=O)c1cnoc1.CN1CCCN2CCCN=C12.COc1ccc(OC)c(... -0.464841\n",
       "4  CN1CCCN2CCCN=C12.COc1ccc(Cl)cc1.COc1ccc(OC)c(P... -1.186082"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "from rxn_yields.data import generate_buchwald_hartwig_rxns\n",
    "df = pd.read_excel('../data/Buchwald-Hartwig/Dreher_and_Doyle_input_data.xlsx', sheet_name='FullCV_01')\n",
    "df['rxn'] = generate_buchwald_hartwig_rxns(df)\n",
    "\n",
    "train_df = df.iloc[:2767][['rxn', 'Output']] \n",
    "test_df = df.iloc[2767:][['rxn', 'Output']] #\n",
    "\n",
    "train_df.columns = ['text', 'labels']\n",
    "test_df.columns = ['text', 'labels']\n",
    "mean = train_df.labels.mean()\n",
    "std = train_df.labels.std()\n",
    "train_df['labels'] = (train_df['labels'] - mean) / std\n",
    "test_df['labels'] = (test_df['labels'] - mean) / std\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Most of the hyperparameter are already fixed by the base model. Here we decided only to tune the `dropout probability` and the `learning rate`. SimpleTransformers has [wandb](https://www.wandb.com) nicely integrated. An example how to setup a hyperparameter sweep can be found in the training scripts. The wandb parameters are read using [dotenv](https://pypi.org/project/python-dotenv/).\n",
    "\n",
    "## Training\n",
    "\n",
    "As you can also be seen from the training scripts, once the data is in the right shape a training run can be started within a few lines of code. \n",
    "\n",
    "For this example we will go with the following parameters,\n",
    "> {dropout=0.7987, learning_rate=0.00009659},\n",
    "\n",
    "and launch a training. We have to reinitiate the BERT model with the correct parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "model_args = {\n",
    "     'num_train_epochs': 15, 'overwrite_output_dir': True,\n",
    "    'learning_rate': 0.00009659, 'gradient_accumulation_steps': 1,\n",
    "    'regression': True, \"num_labels\":1, \"fp16\": False,\n",
    "    \"evaluate_during_training\": False, 'manual_seed': 42,\n",
    "    \"max_seq_length\": 300, \"train_batch_size\": 16,\"warmup_ratio\": 0.00,\n",
    "    \"config\" : { 'hidden_dropout_prob': 0.7987 } \n",
    "}\n",
    "\n",
    "model_path =  pkg_resources.resource_filename(\n",
    "                \"rxnfp\",\n",
    "                f\"models/transformers/bert_pretrained\" # change pretrained to ft to start from the other base model\n",
    ")\n",
    "\n",
    "yield_bert = SmilesClassificationModel(\"bert\", model_path, num_labels=1, \n",
    "                                       args=model_args, use_cuda=torch.cuda.is_available())\n",
    "\n",
    "yield_bert.train_model(train_df, output_dir=f\"outputs_buchwald_hartwig_test_project\", eval_df=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "\n",
    "To load a trained model and make yield predictions. We change the `model_path` to the folder that contains the trained model and use the `predict` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n",
      "Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9f90a0be664c5a88ea07d8f7cf3b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd3afbfd1194f2781cef7b0f3c828cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brc1ccccn1.CN(C)C(=NC(C)(C)C)N(C)C.COc1ccc(OC)c(P(C(C)(C)C)C(C)(C)C)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F.c1ccc(CN(Cc2ccccc2)c2ccno2)cc1>>Cc1ccc(Nc2ccccn2)cc1\n",
      "predicted 37.0 | 38.1 true yield\n",
      "\n",
      "Brc1cccnc1.CC(C)c1cc(C(C)C)c(-c2ccccc2P(C(C)(C)C)C(C)(C)C)c(C(C)C)c1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COC(=O)c1ccno1.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>Cc1ccc(Nc2cccnc2)cc1\n",
      "predicted 15.4 | 14.8 true yield\n",
      "\n",
      "CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.FC(F)(F)c1ccc(Br)cc1.Fc1cccc(F)c1-c1ccno1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1\n",
      "predicted 9.1 | 12.2 true yield\n",
      "\n",
      "CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2)c(C(C)C)c1.CCOC(=O)c1cc(OC)no1.CN1CCCN2CCCN=C12.Cc1ccc(N)cc1.FC(F)(F)c1ccc(Cl)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1\n",
      "predicted 11.8 | 8.3 true yield\n",
      "\n",
      "CN1CCCN2CCCN=C12.COc1ccc(Cl)cc1.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F.c1ccc(-c2ccon2)cc1>>COc1ccc(Nc2ccc(C)cc2)cc1\n",
      "predicted 6.3 | 1.1 true yield\n",
      "\n",
      "CC(C)c1cc(C(C)C)c(-c2ccccc2P(C(C)(C)C)C(C)(C)C)c(C(C)C)c1.CN1CCCN2CCCN=C12.COC(=O)c1cc(-c2ccco2)on1.COc1ccc(I)cc1.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>COc1ccc(Nc2ccc(C)cc2)cc1\n",
      "predicted 45.6 | 44.4 true yield\n",
      "\n",
      "CN(C)C(=NC(C)(C)C)N(C)C.COc1ccc(I)cc1.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.Cc1ccon1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>COc1ccc(Nc2ccc(C)cc2)cc1\n",
      "predicted 46.6 | 53.4 true yield\n",
      "\n",
      "CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1ccc(Cl)cc1.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F.c1ccc(-c2ccno2)cc1>>COc1ccc(Nc2ccc(C)cc2)cc1\n",
      "predicted 0.6 | 1.7 true yield\n",
      "\n",
      "CN(C)C(=NC(C)(C)C)N(C)C.COC(=O)c1ccno1.COc1ccc(OC)c(P(C(C)(C)C)C(C)(C)C)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.FC(F)(F)c1ccc(Br)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1\n",
      "predicted 13.9 | 10.2 true yield\n",
      "\n",
      "CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2)c(C(C)C)c1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COC(=O)c1cc(-c2cccs2)on1.COc1ccc(Cl)cc1.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F>>COc1ccc(Nc2ccc(C)cc2)cc1\n",
      "predicted 0.5 | 0.0 true yield\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "model_path = '../trained_models/buchwald_hartwig/FullCV_01_split_2768/checkpoint-2595-epoch-15'\n",
    "trained_yield_bert = SmilesClassificationModel('bert', model_path,\n",
    "                                  num_labels=1, args={\n",
    "                                      \"regression\": True\n",
    "                                  }, use_cuda=torch.cuda.is_available())\n",
    "\n",
    "yield_predicted = trained_yield_bert.predict(test_df.head(10).text.values)[0]\n",
    "yield_predicted = yield_predicted * std + mean\n",
    "\n",
    "yield_true = test_df.head(10).labels.values\n",
    "yield_true = yield_true * std + mean\n",
    "\n",
    "for rxn, pred, true in zip(test_df.head(10).text.values, yield_predicted, yield_true):\n",
    "    print(rxn)\n",
    "    print(f\"predicted {pred:.1f} | {true:.1f} true yield\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
