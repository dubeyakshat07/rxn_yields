---

title: Training Regression Models on chemical reactions


keywords: fastai
sidebar: home_sidebar

summary: "Here we show how simple it is to train reaction BERTs on any regression task."
description: "Here we show how simple it is to train reaction BERTs on any regression task."
nb_path: "nbs/05_model_training.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_model_training.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Available-tools">Available tools<a class="anchor-link" href="#Available-tools"> </a></h2><p>BERT and related transformer models have revolutionised Natural Language Processing. The implementation of such models is conveniently made available through the <a href="https://github.com/huggingface/transformers">Huggingface Transformers</a> library. We based already based our previous work on reaction fingerprints / classification and atom-mapping on this library. To train the yield regression models in this work, we used the <a href="https://simpletransformers.ai">SimpleTransformers.ai</a>, which contains all you need to add fine-tuning heads on top of transformers, run trainings and evaluations.</p>
<h2 id="SmilesTokenizer">SmilesTokenizer<a class="anchor-link" href="#SmilesTokenizer"> </a></h2><p>One key difference compared to human languages, when compared to chemistry are the tokens and tokenizers. In this work, we use the tokenizer introduced our previous <a href="https://rxn4chemistry.github.io/rxnfp/">rxnfp</a> work with the same regex as in the <a href="https://github.com/pschwllr/MolecularTransformer">Molecular Transformer</a>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">rxnfp.tokenization</span> <span class="kn">import</span> <span class="n">get_default_tokenizer</span><span class="p">,</span> <span class="n">SmilesTokenizer</span>
<span class="kn">from</span> <span class="nn">rdkit.Chem</span> <span class="kn">import</span> <span class="n">rdChemReactions</span>

<span class="n">smiles_tokenizer</span> <span class="o">=</span> <span class="n">get_default_tokenizer</span><span class="p">()</span>

<span class="n">reaction_smiles</span> <span class="o">=</span> <span class="s1">&#39;CC(C)[C@@H](C)CCBr.[Na]C#N&gt;&gt;CC([C@@H](C)CCC#N)C&#39;</span>
<span class="n">rxn</span> <span class="o">=</span> <span class="n">rdChemReactions</span><span class="o">.</span><span class="n">ReactionFromSmarts</span><span class="p">(</span><span class="n">reaction_smiles</span><span class="p">,</span><span class="n">useSmiles</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">smiles_tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">reaction_smiles</span><span class="p">))</span>
<span class="n">rxn</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre><span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> W&amp;B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.
Setting &#39;max_len_single_sentence&#39; is now deprecated. This value is automatically set up.
Setting &#39;max_len_sentences_pair&#39; is now deprecated. This value is automatically set up.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;C&#39;, &#39;C&#39;, &#39;(&#39;, &#39;C&#39;, &#39;)&#39;, &#39;[C@@H]&#39;, &#39;(&#39;, &#39;C&#39;, &#39;)&#39;, &#39;C&#39;, &#39;C&#39;, &#39;Br&#39;, &#39;.&#39;, &#39;[Na]&#39;, &#39;C&#39;, &#39;#&#39;, &#39;N&#39;, &#39;&gt;&gt;&#39;, &#39;C&#39;, &#39;C&#39;, &#39;(&#39;, &#39;[C@@H]&#39;, &#39;(&#39;, &#39;C&#39;, &#39;)&#39;, &#39;C&#39;, &#39;C&#39;, &#39;C&#39;, &#39;#&#39;, &#39;N&#39;, &#39;)&#39;, &#39;C&#39;]
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea output_execute_result">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As the tokenizer is normally hard-coded in the SimpleTransformers library we need to change it, we therefore create a <code>SmilesClassificationModel</code> class, as seen in the <a href="/rxn_yields/core.html"><code>core</code></a> module.</p>
<div class="highlight"><pre><span></span><span class="n">MODEL_CLASSES</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;bert&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">BertConfig</span><span class="p">,</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">SmilesTokenizer</span><span class="p">),</span>
        <span class="p">}</span>
</pre></div>
<p>Once this is done, the SimpleTransformers library can be used as usual.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Pretrained-reaction-BERT-models">Pretrained reaction BERT models<a class="anchor-link" href="#Pretrained-reaction-BERT-models"> </a></h2><p>There are currently two reaction BERT models in the <code>rxnfp</code> library - <code>pretrained</code> (trained with on a reaction MLM task) and <code>ft</code> (additionally trained on a reaction classification task). For this example, we will use the <code>pretrained</code> model as starting point for the training of our Yield-BERT. On the Buchwald-Hartwig reactions both base models performed similarly.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pkg_resources</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">rxnfp.models</span> <span class="kn">import</span> <span class="n">SmilesClassificationModel</span>
<span class="n">model_path</span> <span class="o">=</span>  <span class="n">pkg_resources</span><span class="o">.</span><span class="n">resource_filename</span><span class="p">(</span>
                <span class="s2">&quot;rxnfp&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;models/transformers/bert_pretrained&quot;</span> <span class="c1"># change pretrained to ft to start from the other base model</span>
<span class="p">)</span>
<span class="n">yield_bert</span> <span class="o">=</span> <span class="n">SmilesClassificationModel</span><span class="p">(</span><span class="s1">&#39;bert&#39;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Setting &#39;max_len_single_sentence&#39; is now deprecated. This value is automatically set up.
Setting &#39;max_len_sentences_pair&#39; is now deprecated. This value is automatically set up.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Prepare-the-data">Prepare the data<a class="anchor-link" href="#Prepare-the-data"> </a></h2><p>Load the reaction SMILES and yield values into a DataFrame with columns <code>['text', 'labels']</code>.</p>
<p>The same procedure could be applied to any reaction (or molecule) regression task.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">rxn_yields.data</span> <span class="kn">import</span> <span class="n">generate_buchwald_hartwig_rxns</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;../data/Buchwald-Hartwig/Dreher_and_Doyle_input_data.xlsx&#39;</span><span class="p">,</span> <span class="n">sheet_name</span><span class="o">=</span><span class="s1">&#39;FullCV_01&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;rxn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generate_buchwald_hartwig_rxns</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">2767</span><span class="p">][[</span><span class="s1">&#39;rxn&#39;</span><span class="p">,</span> <span class="s1">&#39;Output&#39;</span><span class="p">]]</span> 
<span class="n">test_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">2767</span><span class="p">:][[</span><span class="s1">&#39;rxn&#39;</span><span class="p">,</span> <span class="s1">&#39;Output&#39;</span><span class="p">]]</span> <span class="c1">#</span>

<span class="n">train_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">test_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
<span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>labels</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1...</td>
      <td>1.387974</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Brc1ccccn1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C...</td>
      <td>-0.796876</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2...</td>
      <td>-0.827835</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CCOC(=O)c1cnoc1.CN1CCCN2CCCN=C12.COc1ccc(OC)c(...</td>
      <td>-0.464841</td>
    </tr>
    <tr>
      <th>4</th>
      <td>CN1CCCN2CCCN=C12.COc1ccc(Cl)cc1.COc1ccc(OC)c(P...</td>
      <td>-1.186082</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyperparameter-tuning">Hyperparameter tuning<a class="anchor-link" href="#Hyperparameter-tuning"> </a></h2><p>Most of the hyperparameter are already fixed by the base model. Here we decided only to tune the <code>dropout probability</code> and the <code>learning rate</code>. SimpleTransformers has <a href="https://www.wandb.com">wandb</a> nicely integrated. An example how to setup a hyperparameter sweep can be found in the training scripts. The wandb parameters are read using <a href="https://pypi.org/project/python-dotenv/">dotenv</a>.</p>
<h2 id="Training">Training<a class="anchor-link" href="#Training"> </a></h2><p>As you can also be seen from the training scripts, once the data is in the right shape a training run can be started within a few lines of code.</p>
<p>For this example we will go with the following parameters,</p>
<blockquote><p>{dropout=0.7987, learning_rate=0.00009659},</p>
</blockquote>
<p>and launch a training. We have to reinitiate the BERT model with the correct parameters.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_args</span> <span class="o">=</span> <span class="p">{</span>
     <span class="s1">&#39;num_train_epochs&#39;</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span> <span class="s1">&#39;overwrite_output_dir&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.00009659</span><span class="p">,</span> <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;regression&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;num_labels&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;fp16&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;evaluate_during_training&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">&#39;manual_seed&#39;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
    <span class="s2">&quot;max_seq_length&quot;</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span> <span class="s2">&quot;train_batch_size&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span><span class="s2">&quot;warmup_ratio&quot;</span><span class="p">:</span> <span class="mf">0.00</span><span class="p">,</span>
    <span class="s2">&quot;config&quot;</span> <span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;hidden_dropout_prob&#39;</span><span class="p">:</span> <span class="mf">0.7987</span> <span class="p">}</span> 
<span class="p">}</span>

<span class="n">model_path</span> <span class="o">=</span>  <span class="n">pkg_resources</span><span class="o">.</span><span class="n">resource_filename</span><span class="p">(</span>
                <span class="s2">&quot;rxnfp&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;models/transformers/bert_pretrained&quot;</span> <span class="c1"># change pretrained to ft to start from the other base model</span>
<span class="p">)</span>

<span class="n">yield_bert</span> <span class="o">=</span> <span class="n">SmilesClassificationModel</span><span class="p">(</span><span class="s2">&quot;bert&quot;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                       <span class="n">args</span><span class="o">=</span><span class="n">model_args</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>

<span class="n">yield_bert</span><span class="o">.</span><span class="n">train_model</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;outputs_buchwald_hartwig_test_project&quot;</span><span class="p">,</span> <span class="n">eval_df</span><span class="o">=</span><span class="n">test_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Predictions">Predictions<a class="anchor-link" href="#Predictions"> </a></h2><p>To load a trained model and make yield predictions. We change the <code>model_path</code> to the folder that contains the trained model and use the <code>predict</code> method.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;../trained_models/buchwald_hartwig/FullCV_01_split_2768/checkpoint-2595-epoch-15&#39;</span>
<span class="n">trained_yield_bert</span> <span class="o">=</span> <span class="n">SmilesClassificationModel</span><span class="p">(</span><span class="s1">&#39;bert&#39;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span>
                                  <span class="n">num_labels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">{</span>
                                      <span class="s2">&quot;regression&quot;</span><span class="p">:</span> <span class="kc">True</span>
                                  <span class="p">},</span> <span class="n">use_cuda</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">())</span>

<span class="n">yield_predicted</span> <span class="o">=</span> <span class="n">trained_yield_bert</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">values</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">yield_predicted</span> <span class="o">=</span> <span class="n">yield_predicted</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span>

<span class="n">yield_true</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">values</span>
<span class="n">yield_true</span> <span class="o">=</span> <span class="n">yield_true</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span>

<span class="k">for</span> <span class="n">rxn</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">true</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">yield_predicted</span><span class="p">,</span> <span class="n">yield_true</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">rxn</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;predicted </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">true</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> true yield&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Setting &#39;max_len_single_sentence&#39; is now deprecated. This value is automatically set up.
Setting &#39;max_len_sentences_pair&#39; is now deprecated. This value is automatically set up.
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>

Brc1ccccn1.CN(C)C(=NC(C)(C)C)N(C)C.COc1ccc(OC)c(P(C(C)(C)C)C(C)(C)C)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F.c1ccc(CN(Cc2ccccc2)c2ccno2)cc1&gt;&gt;Cc1ccc(Nc2ccccn2)cc1
predicted 37.0 | 38.1 true yield

Brc1cccnc1.CC(C)c1cc(C(C)C)c(-c2ccccc2P(C(C)(C)C)C(C)(C)C)c(C(C)C)c1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COC(=O)c1ccno1.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;Cc1ccc(Nc2cccnc2)cc1
predicted 15.4 | 14.8 true yield

CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.FC(F)(F)c1ccc(Br)cc1.Fc1cccc(F)c1-c1ccno1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1
predicted 9.1 | 12.2 true yield

CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2)c(C(C)C)c1.CCOC(=O)c1cc(OC)no1.CN1CCCN2CCCN=C12.Cc1ccc(N)cc1.FC(F)(F)c1ccc(Cl)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1
predicted 11.8 | 8.3 true yield

CN1CCCN2CCCN=C12.COc1ccc(Cl)cc1.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F.c1ccc(-c2ccon2)cc1&gt;&gt;COc1ccc(Nc2ccc(C)cc2)cc1
predicted 6.3 | 1.1 true yield

CC(C)c1cc(C(C)C)c(-c2ccccc2P(C(C)(C)C)C(C)(C)C)c(C(C)C)c1.CN1CCCN2CCCN=C12.COC(=O)c1cc(-c2ccco2)on1.COc1ccc(I)cc1.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;COc1ccc(Nc2ccc(C)cc2)cc1
predicted 45.6 | 44.4 true yield

CN(C)C(=NC(C)(C)C)N(C)C.COc1ccc(I)cc1.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.Cc1ccon1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;COc1ccc(Nc2ccc(C)cc2)cc1
predicted 46.6 | 53.4 true yield

CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COc1ccc(Cl)cc1.COc1ccc(OC)c(P([C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)[C@]23C[C@H]4C[C@H](C[C@H](C4)C2)C3)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F.c1ccc(-c2ccno2)cc1&gt;&gt;COc1ccc(Nc2ccc(C)cc2)cc1
predicted 0.6 | 1.7 true yield

CN(C)C(=NC(C)(C)C)N(C)C.COC(=O)c1ccno1.COc1ccc(OC)c(P(C(C)(C)C)C(C)(C)C)c1-c1c(C(C)C)cc(C(C)C)cc1C(C)C.Cc1ccc(N)cc1.FC(F)(F)c1ccc(Br)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;Cc1ccc(Nc2ccc(C(F)(F)F)cc2)cc1
predicted 13.9 | 10.2 true yield

CC(C)c1cc(C(C)C)c(-c2ccccc2P(C2CCCCC2)C2CCCCC2)c(C(C)C)c1.CCN=P(N=P(N(C)C)(N(C)C)N(C)C)(N(C)C)N(C)C.COC(=O)c1cc(-c2cccs2)on1.COc1ccc(Cl)cc1.Cc1ccc(N)cc1.O=S(=O)(O[Pd]1c2ccccc2-c2ccccc2[NH2]1)C(F)(F)F&gt;&gt;COc1ccc(Nc2ccc(C)cc2)cc1
predicted 0.5 | 0.0 true yield

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

